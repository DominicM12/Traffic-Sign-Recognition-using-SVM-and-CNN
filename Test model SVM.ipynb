{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "frameWidth= 640   #camera resolution\n",
    "frameHeight= 480\n",
    "brightness= 180\n",
    "threshold=0.90 #probability threshold\n",
    "font= cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########Setting up the camera\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,frameWidth)\n",
    "cap.set(4,frameHeight)\n",
    "cap.set(10,brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "import pickle\n",
    "with open('SVM_model','rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grayscale(img):\n",
    "#    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#    return img\n",
    "# def equalize(img):\n",
    "#   img = cv2.equalizeHist(img)\n",
    "#   return img\n",
    "\n",
    "# convert RGB images to grayscale\n",
    "def grayscale(rgb_images):\n",
    "    res = np.zeros(shape=(len(rgb_images), \n",
    "                          rgb_images.shape[1],\n",
    "                          rgb_images.shape[2]))\n",
    "    for i in range(len(rgb_images)):\n",
    "        res[i] = cv2.cvtColor(rgb_images[i], cv2.COLOR_RGB2GRAY)\n",
    "    return res\n",
    "\n",
    "# scale image features to 0 mean and unit variance\n",
    "def normalize(images):\n",
    "    return (images - 128) / 128\n",
    "\n",
    "def preprocessing(img):\n",
    "  img = grayscale(img)\n",
    "  img = normalize(img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xde556130::Set<1,-1,-1>,struct cv::impl::A0xde556130::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dd5b96740636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgOriginal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processed image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-65d6ef8d1c67>\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-65d6ef8d1c67>\u001b[0m in \u001b[0;36mgrayscale\u001b[1;34m(rgb_images)\u001b[0m\n\u001b[0;32m     12\u001b[0m                           rgb_images.shape[2]))\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-6sxsq0tp\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xde556130::Set<1,-1,-1>,struct cv::impl::A0xde556130::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": [
    "def getClassname(classNo):\n",
    "    if   classNo == 0: return 'Speed limit 20 km/h'\n",
    "    elif classNo == 1 : return 'Speed limit 30 km/h'\n",
    "    elif classNo == 2 : return 'Speed limit 50 km/h'\n",
    "    elif classNo == 3 : return 'Speed limit 60 km/h'\n",
    "    elif classNo == 4 : return 'Speed limit 70 km/h'\n",
    "    elif classNo == 5 : return 'Speed limit 80 km/h'\n",
    "    elif classNo == 6 : return 'End of speed limit 80km/h'\n",
    "    elif classNo == 7 : return 'Speed limit 100 km/h'\n",
    "    elif classNo == 8 : return 'Speed limit 120 km/h'\n",
    "    elif classNo == 9 : return 'No passing'\n",
    "    elif classNo == 10 : return 'No passing for vehicle over 3.5 metric tons'\n",
    "    elif classNo == 11 : return 'Right-of - way at the next destination'\n",
    "    elif classNo == 12 : return 'Priority Road'\n",
    "    elif classNo == 13 : return 'Yield'\n",
    "    elif classNo == 14 : return 'Stop'\n",
    "    elif classNo == 15 : return 'No vehicles'\n",
    "    elif classNo == 16 : return ' vehicle over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17 : return 'No entry'\n",
    "    elif classNo == 18 : return 'General caution'\n",
    "    elif classNo == 19 : return 'Dangerous curve to the left'\n",
    "    elif classNo == 20 : return 'Dangerous curve to the right'\n",
    "    elif classNo == 21 : return 'Double curve'\n",
    "    elif classNo == 22 : return 'Bumpy road'\n",
    "    elif classNo == 23 : return 'Slippery road'\n",
    "    elif classNo == 24 : return 'Road narrows on the right'\n",
    "    elif classNo == 25 : return 'Road work'\n",
    "    elif classNo == 26 : return 'Traffic signals'\n",
    "    elif classNo == 27 : return 'Pedestrians'\n",
    "    elif classNo == 28 : return 'Children crossing'\n",
    "    elif classNo == 29 : return 'Bicycle crossing'\n",
    "    elif classNo == 30 : return 'Beware of ice/snow'\n",
    "    elif classNo == 31 : return 'Wild animals crossing'\n",
    "    elif classNo == 32 : return 'End of all speed and passing limits'\n",
    "    elif classNo == 33 : return 'Turn right ahead'\n",
    "    elif classNo == 34 : return 'Turn left ahead'\n",
    "    elif classNo == 35 : return 'Ahead only'\n",
    "    elif classNo == 36 : return 'Go straight or right'\n",
    "    elif classNo == 37 : return 'Go straight or left'\n",
    "    elif classNo == 38 : return 'Keep right'\n",
    "    elif classNo == 39 : return 'Keep left'\n",
    "    elif classNo == 40 : return 'Roundabout Mandatory'\n",
    "    elif classNo == 41 : return 'End of no passing'\n",
    "    elif classNo == 42 : return 'End of no passing by vehicles over 3.5 metric tons'\n",
    "\n",
    "while True:\n",
    "    ##Read image\n",
    "    success,imgOriginal=cap.read()\n",
    "    \n",
    "    ##process image\n",
    "    img=np.asarray(imgOriginal)\n",
    "    img=cv2.resize(img,(32,32))\n",
    "    img=preprocessing(img)\n",
    "    cv2.imshow(\"Processed image\",img)\n",
    "    img=img.reshape(32,32,3)\n",
    "    cv2.putText(imgOriginal,\"CLASS: \",(20,35),font,0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(imgOriginal, \"PROBABILITY: \", (20,75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    ##predict image\n",
    "    predictions=model.predict(img)\n",
    "    classIndex=model.predict_classes(img)\n",
    "    probabilityValue=np.amax(predictions)\n",
    "    if probabilityValue > threshold:\n",
    "        cv2.putText(imgOriginal,str(classIndex)+\" \"+ str(getClassName(classIndex)),(120,35),font,0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(imgOriginal,str(round(probabilityValue*100,2))+\" % \",(180,75),font,0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Result\",imgOriginal)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "#     # # PROCESS IMAGE\n",
    "# img = np.array(imgOrignal)\n",
    "# img = cv2.resize(imgOrignal, (32, 32))\n",
    "# img = preprocessing(img)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "  \n",
    "# cv2.imshow(\"Processed Image\", img)\n",
    "# img = img.reshape(1, 32, 32, 1)\n",
    "# cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "# cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "# # PREDICT IMAGE\n",
    "# predictions = model.predict(img)\n",
    "# classIndex = model.predict_classes(img)\n",
    "# probabilityValue =np.amax(predictions)\n",
    "# if probabilityValue > threshold:\n",
    "#     print(classIndex)\n",
    "#     print(getCalssName(classIndex))\n",
    "#     plt.text(1, 1, f\"CLASS: {classIndex} {getCalssName(classIndex)}\\nPROBABILITY: {round(probabilityValue*100,2)}%\" ,ha=\"left\",va=\"top\", bbox=dict(fill=False, edgecolor='red', linewidth=2))\n",
    "#     plt.text(1, 5, f\"PROBABILITY: {round(probabilityValue*100,2)}%\", bbox=dict(fill=False, edgecolor='red', linewidth=2))\n",
    "\n",
    "# plt.imshow(imgOrignal)\n",
    "# plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
